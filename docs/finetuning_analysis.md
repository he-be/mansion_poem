# ファインチューニングによるオフライン実行の実現性検討

## エグゼクティブサマリー

**結論: 小型モデル（〜20B）のファインチューニングでは、Geminiレベルの品質達成は困難**

本プロジェクトのポエム生成タスクは極めて高度な創造的能力を要求するため、ファインチューニングだけでは小型モデルの根本的な能力不足を補うことはできません。しかし、**代替アプローチ**により、オフラインデモのユースケースは十分実現可能です。

---

## 1. 現状分析

### 1.1 プロジェクトのデータ特性

```
データ構造:
- 現実カード: 89枚
- 言い換えポエム: 267種類（平均3種類/カード）
- キャッチコピー: 110種類
- ゲームフロー: 5枚選択 → 各カードに1つの言い換え選択 → ポエム生成

プロンプト特性:
- プロンプト長: 約1,500トークン（詳細な指示、文体・構造要件を含む）
- 出力長: 180-240文字のポエム + タイトル（約250トークン）
- 温度設定: 0.9（高い創造性を要求）

理論的組み合わせ数:
- カード選択: C(89, 5) ≈ 4,300万通り
- 言い換え選択: 3^5 = 243通り/カードセット
- タイトル候補: C(110, 20) ≈ 天文学的
```

### 1.2 現在のコスト（Gemini Flash）

```
単価:
- プロンプト: 1,500トークン × $0.00001875/1K = $0.000028
- 生成: 250トークン × $0.000075/1K = $0.000019
- 合計: $0.000047/リクエスト

月間想定:
- 100リクエスト/月: 約0.7円/月
- 1,000リクエスト/月: 約7円/月

データセット生成コスト:
- 5,000件: 約35円
```

### 1.3 品質ギャップの分析

**20Bモデルの出力例:**
```
未来資産を、住む。
都会の喧騒を離れ、静謐な空間へ。北向きの光が差し込み、知的創作の息吹を呼び覚ます。
コンクリートの本質が洗練された感性を映し出す。
```

**Geminiの出力例:**
```
都市を、自然体で生きる。
大地の息吹は、時に力強いダイナミズムを伝える。その傍ら、流れる水面は、
幾千の季節を静かに映し出す。ここは、大きな自然の律動と、人の営みが交差する場所。
```

**差異の本質:**
- **詩的表現力**: Geminiは比喩・隠喩が豊富で、感情的な響きが強い
- **文章構成**: 段落間の論理的つながりが自然（対比構造、時間軸、空間軸）
- **語彙選択**: より洗練された表現（「幾千の季節」「律動」など）
- **指示理解**: 「ネガティブ条件の完全な隠蔽」という微妙な要求への対応

---

## 2. ファインチューニングの実現性：批判的検討

### 2.1 根本的な限界

#### ❌ ファインチューニングで解決**できない**問題

1. **ベースモデルの能力上限**
   - ファインチューニングは既存能力の「調整」であり、「創造」ではない
   - 詩的表現力や高度な文章構成能力は、モデルサイズに強く依存
   - 20Bモデルには、Gemini（推定1,000B+規模）の言語理解力がない

2. **複雑な指示理解**
   - 1,500トークンの詳細な指示を正確に理解し、全てを満たす能力
   - 「ネガティブ条件を隠蔽しつつ、ポエムの魂を抽出して再創造」という抽象的要求
   - 小型モデルでは、指示の一部しか反映できない（例: 文字数制約は守るが、対比構造は作れない）

3. **創造性の質**
   - temperature=0.9での高品質な創造的出力
   - 単なるテンプレート的生成ではない、真に独創的な表現

#### ✅ ファインチューニングで改善**できる**範囲

1. **出力フォーマットの安定化**
   - JSON形式の出力、文字数制約の遵守
   - 特定の語彙の使用/回避

2. **タスク特化の効率化**
   - プロンプトの短縮（指示を学習させることで）
   - 推論速度の向上

3. **スタイルの模倣（限定的）**
   - 体言止めの使用、読点の配置など表面的なスタイル
   - ただし、内容の質や深みは向上しない

### 2.2 データ量の観点

**一般的な指針:**
- ファインチューニング: 数百〜数千サンプル（タスク特化）
- 高品質な創造的タスク: 1万〜10万サンプル

**本プロジェクトの場合:**

| データ量 | 生成コスト | 期待される効果 | 評価 |
|---------|----------|--------------|------|
| 500件 | 約3.5円 | フォーマット安定化 | △ |
| 5,000件 | 約35円 | スタイル模倣開始 | △ |
| 50,000件 | 約350円 | スタイル安定、表現の多様性向上 | ○ |

**重要な洞察:**
- データ量を増やしても、ベースモデルの能力上限を超えることはできない
- 5万件のデータで350円という低コストは魅力的だが、**品質向上の保証はない**
- 20Bモデルでは、どれだけデータを増やしても、Geminiの「幾千の季節を静かに映し出す」のような表現は生成できない可能性が高い

### 2.3 技術的制約

**小型モデル（20B以下）の限界:**
```
パラメータ数と能力の関係（経験則）:
- 7B以下: 基本的な指示理解、テンプレート的生成
- 13-20B: ある程度の創造性、中程度の複雑な指示理解
- 70B+: 高度な創造性、複雑な指示理解
- 100B+: Gemini級の詩的表現力
```

**量子化の影響:**
- 4bit量子化: パラメータ数は保持されるが、精度が低下
- 創造的タスクでは、量子化による品質劣化が顕著に現れる

---

## 3. データセット作成方法（実施する場合）

### 3.1 基本戦略

ファインチューニングを試す場合の、効率的なデータセット作成方法を提案します。

#### ステップ1: 多様なサンプル生成

```python
# 疑似コード（実装イメージ）

# 1. カードの組み合わせパターンを生成
def generate_card_combinations(num_samples=5000):
    combinations = []
    for i in range(num_samples):
        # 5枚のカードをランダム選択
        selected_cards = random.sample(all_cards, 5)
        # 各カードの言い換えをランダム選択
        selected_pairs = [
            {
                "condition": card,
                "poem": random.choice(card.poems)
            }
            for card in selected_cards
        ]
        # タイトル候補20個をランダム選択
        title_candidates = random.sample(all_catchphrases, 20)

        combinations.append({
            "pairs": selected_pairs,
            "titles": title_candidates
        })
    return combinations

# 2. Gemini APIで高品質なポエムを生成
async def generate_dataset(combinations):
    dataset = []
    for combo in combinations:
        # プロンプト構築（現在のprompt.txtを使用）
        prompt = build_prompt(combo["pairs"], combo["titles"])

        # Gemini APIで生成
        result = await call_gemini_api(prompt)

        dataset.append({
            "input": {
                "pairs": combo["pairs"],
                "title_candidates": combo["titles"]
            },
            "output": {
                "title": result["title"],
                "poem": result["poem"]
            }
        })

        # レート制限対策（60リクエスト/分）
        await sleep(1)

    return dataset
```

#### ステップ2: データの多様性確保

**カバレッジ戦略:**

1. **カテゴリバランス**
   ```
   - 交通アクセス: 20%
   - 建物設備: 20%
   - 環境: 20%
   - 管理: 20%
   - その他: 20%
   ```

2. **難易度の分散**
   ```
   - 低難易度（strength: -1〜-2）: 30%
   - 中難易度（strength: -3）: 40%
   - 高難易度（strength: -4〜-5）: 30%
   ```

3. **組み合わせパターン**
   ```
   - 同一カテゴリ集中: 10%
   - バランス型: 60%
   - 極端な組み合わせ: 30%
   ```

#### ステップ3: データ品質管理

**Geminiの出力は既に高品質という前提**があるため、人力レビューは不要。ただし：

```python
# 自動品質チェック
def validate_output(output):
    checks = [
        # 1. フォーマット検証
        "title" in output and "poem" in output,

        # 2. 文字数検証
        180 <= len(output["poem"]) <= 240,

        # 3. タイトルが候補に含まれるか
        output["title"] in title_candidates,

        # 4. JSON解析可能か
        is_valid_json(output)
    ]
    return all(checks)

# 不合格サンプルは再生成
```

### 3.2 ファインチューニング形式

**ChatML形式の例:**

```json
{
  "messages": [
    {
      "role": "system",
      "content": "あなたは一流不動産広告のクリエイティブディレクターです。選択されたポエムカードの本質を抽出し、心に響く広告本文とタイトルを創造してください。\n\n【出力形式】JSON形式: {\"title\": \"選択したキャッチコピー\", \"poem\": \"生成した広告本文\"}\n\n【文章構造】3-4段落、180-240文字\n【文体】短文を「。」で区切る、断定的でリズムの良い文体\n【重要】元のネガティブな条件を完全に隠蔽すること"
    },
    {
      "role": "user",
      "content": "【選択されたカードペア】\n1. 交通アクセス: 駅徒歩15分 → 都心と程よい距離を保つ、静寂の丘。\n2. 建物設備: 北向き → 安定した自然光が、創作活動を支える。\n...\n\n【タイトル選択候補】\n1. 未来資産を、住む。\n2. 都市を、自然体で生きる。\n..."
    },
    {
      "role": "assistant",
      "content": "{\"title\": \"都市を、自然体で生きる。\", \"poem\": \"大地の息吹は、時に力強いダイナミズムを伝える。その傍ら、流れる水面は、幾千の季節を静かに映し出す...\"}"
    }
  ]
}
```

**効率化のポイント:**
- システムプロンプトを簡潔にして、詳細な指示は学習に任せる
- モデルがパターンを学習すれば、プロンプトを大幅に短縮できる可能性

### 3.3 実装スクリプト（概要）

```bash
# scripts/generate_ft_dataset.ts

import { generateCardCombinations } from './lib/combinations'
import { callGeminiAPI } from './lib/gemini'
import { validateOutput } from './lib/validation'

const NUM_SAMPLES = 5000
const OUTPUT_FILE = 'ft_dataset.jsonl'

async function main() {
  console.log(`Generating ${NUM_SAMPLES} samples...`)

  const combinations = generateCardCombinations(NUM_SAMPLES)
  const dataset = []

  for (let i = 0; i < combinations.length; i++) {
    const combo = combinations[i]

    // プロンプト構築
    const prompt = buildPrompt(combo.pairs, combo.titles)

    // Gemini API呼び出し
    const output = await callGeminiAPI(prompt)

    // 検証
    if (!validateOutput(output, combo.titles)) {
      console.warn(`Sample ${i} failed validation, retrying...`)
      continue
    }

    // データセット追加
    dataset.push(formatForFineTuning(combo, output))

    // 進捗表示
    if ((i + 1) % 100 === 0) {
      console.log(`Progress: ${i + 1}/${NUM_SAMPLES}`)
    }

    // レート制限対策（60req/min → 1req/sec）
    await sleep(1000)
  }

  // JSONL形式で保存
  writeFileSync(OUTPUT_FILE, dataset.map(JSON.stringify).join('\n'))

  console.log(`Dataset saved to ${OUTPUT_FILE}`)
  console.log(`Total cost: $${(NUM_SAMPLES * 0.000047).toFixed(2)}`)
}
```

---

## 4. 必要データ量の見積もり

### 4.1 段階的アプローチ

| フェーズ | データ量 | コスト | 所要時間 | 目的 | 期待される効果 |
|---------|---------|--------|----------|------|--------------|
| **Phase 0: 検証** | 100件 | 0.7円 | 2分 | 実現性確認 | フォーマットの安定性確認 |
| **Phase 1: 最小実証** | 500件 | 3.5円 | 10分 | 基本動作確認 | 出力フォーマット安定化 |
| **Phase 2: 標準** | 5,000件 | 35円 | 83分 | スタイル学習 | 文体模倣、基本的な表現パターン |
| **Phase 3: 大規模** | 50,000件 | 350円 | 14時間 | 品質向上 | 表現の多様性、安定した品質 |

**推奨戦略:**

```
1. Phase 0（100件）で実現性を検証
   ↓
2. 品質が許容範囲内ならPhase 1（500件）でベースライン作成
   ↓
3. 明確な改善が見られればPhase 2（5,000件）で本格実装
   ↓
4. さらなる品質向上が必要ならPhase 3（50,000件）
```

**重要な判断基準:**
- Phase 0で「Geminiの20%の品質」に到達できなければ、このアプローチは断念
- Phase 1で「50%の品質」に到達できなければ、データ量を増やしても無駄
- Phase 2で「70%以上の品質」に到達できれば、Phase 3を検討

### 4.2 コスト分析

**Gemini APIでのデータ生成:**
```
100件:     $0.0047   ≈ 0.7円   (2分)
500件:     $0.0235   ≈ 3.5円   (10分)
5,000件:   $0.235    ≈ 35円    (83分)
50,000件:  $2.35     ≈ 350円   (14時間)
```

**ファインチューニングコスト（概算）:**

主要なプロバイダーの価格例：
- **OpenAI GPT-3.5**: $0.0080/1K tokens（トレーニング）
- **Google Vertex AI**: $0.008/1K tokens（トレーニング）
- **Together.ai (Llama 2 70B)**: $0.0008/1K tokens

```
5,000サンプルの場合（1サンプル平均2,000トークン = 10M tokens）:
- OpenAI: $80
- Together.ai: $8

推論コスト（ファインチューニング後）:
- ローカル実行: $0（ハードウェア費用のみ）
- クラウド: $0.001〜0.01/リクエスト
```

**総コスト比較:**

| アプローチ | 初期コスト | 運用コスト（100リクエスト） | 備考 |
|-----------|-----------|--------------------------|------|
| 現状（Gemini） | $0 | $0.0047 ≈ 0.7円 | 最高品質 |
| FT（OpenAI） | $80 + $35 | $0.10 ≈ 15円 | クラウド推論 |
| FT（ローカル20B） | $8 + $35 | $0 | 品質低下のリスク |
| FT（ローカル70B+） | $8 + $35 | $0 | 要高性能GPU |

**結論:**
- 現状のGemini APIは極めて低コストで、ファインチューニングの経済的メリットは薄い
- オフライン実行が必須の場合のみ、ファインチューニングを検討する価値がある

---

## 5. 推奨アプローチ：代替案の提案

### 5.1 ❌ 推奨しない: 20Bモデルのファインチューニング

**理由:**
1. ベースモデルの能力不足が明白（既存の生成例から）
2. データ量を増やしても品質向上の保証がない
3. 開発・検証コストに見合う効果が得られない可能性が高い

---

### 5.2 ✅ 推奨案1: ローカルでより大型のモデルを使用

**提案: Llama 3.1 70B（4bit量子化）**

```
要件:
- VRAM: 約40GB（RTX 3090 × 2枚、または RTX 4090 × 1枚）
- RAM: 64GB以上
- ストレージ: 50GB

利点:
- ファインチューニング不要
- Geminiに近い品質が期待できる
- オフライン実行可能

実装:
- LM Studio、Ollama、text-generation-webuiなどで実行
- OpenAI互換APIで既存コードとほぼそのまま連携可能
```

**コスト比較:**
- GPU: RTX 4090（約30万円）× 1枚
- vs ファインチューニング: データ生成35円 + トレーニング8円 = 43円（ただし品質不明）

**判断:**
- 継続的なオフラインデモが必要 → GPU投資を検討
- 単発のデモ → 次の案を推奨

---

### 5.3 ✅ 推奨案2: プロンプト簡素化 + 20Bモデル

**戦略: タスクを小型モデルでも対応可能にする**

#### 改善案A: 2段階生成

```
ステップ1: 要素抽出（小型モデルで可能）
入力: 選択されたカードペア
出力: キーワードリスト

ステップ2: ポエム生成（簡略化されたプロンプト）
入力: キーワード + 簡潔な指示（300トークン程度）
出力: ポエム
```

**メリット:**
- 各ステップのタスクが単純になり、小型モデルでも対応可能
- プロンプト長が大幅に短縮（1,500 → 300トークン）

**デメリット:**
- 処理が複雑化
- 品質は依然として劣る可能性

#### 改善案B: テンプレートベース生成

```
1. カードの特徴を分析
2. 事前定義されたテンプレートから選択
3. テンプレートの穴埋め（小型モデルで可能）
4. 文章の微調整
```

**メリット:**
- 安定した品質
- 小型モデルでも実行可能

**デメリット:**
- 創造性が大幅に低下
- テンプレート作成に手間がかかる

---

### 5.4 ✅ 推奨案3: 事前生成 + オフライン配信

**オフラインデモ用の現実的なアプローチ**

```
準備:
1. 代表的な組み合わせ1,000パターンをGeminiで事前生成
   コスト: 1,000 × $0.000047 ≈ 7円

2. 生成結果をJSONファイルとして保存
   {
     "pattern_id": "hash_of_selected_pairs",
     "title": "...",
     "poem": "..."
   }

デモ時:
1. ユーザーがカードを選択
2. 選択パターンのハッシュを計算
3. 事前生成データから該当結果を返す
4. 該当なし → フォールバック（ランダムまたはテンプレート）
```

**メリット:**
- 極めて低コスト（7円）
- Geminiの品質を維持
- 完全オフライン動作
- 実装が簡単

**デメリット:**
- 全組み合わせをカバーできない
- 「生成感」が薄れる（デモには問題ない）

**カバレッジ戦略:**
```
1,000パターンの選び方:
- 頻出組み合わせ: 300パターン（カテゴリバランス重視）
- ランダムサンプル: 500パターン
- エッジケース: 200パターン（極端な組み合わせ）

期待カバレッジ:
- 実際のユーザー選択の約30-50%はヒット
- 残りはフォールバック（品質は劣るが、デモには十分）
```

---

### 5.5 ✅ 推奨案4: Geminiプロンプトキャッシング

**Google Gemini 1.5のContext Caching機能を活用**

```
仕組み:
- プロンプトの固定部分（指示、タイトル候補など）をキャッシュ
- 可変部分（選択されたカードペア）のみを毎回送信
- キャッシュヒット時、プロンプトコストが90%削減

コスト削減例:
- 通常: $0.000047/リクエスト
- キャッシュ利用: $0.000010/リクエスト（約80%削減）

制約:
- オンライン実行が必要
- キャッシュTTL: 1時間（定期的にリフレッシュ必要）
```

**適用場面:**
- デモイベントで短時間に多数のリクエストがある場合
- オンライン環境が利用可能な場合

---

## 6. 実装ロードマップ（推奨案3を採用する場合）

### Phase 1: 事前生成データの作成（推奨開始点）

```bash
# 1週目: スクリプト作成
- scripts/generate_precomputed_poems.ts の実装
- 1,000パターンの組み合わせ生成ロジック
- Gemini API呼び出しとデータ保存

# 2週目: データ生成実行
- 1,000パターンを生成（約17分、7円）
- データ検証とフォーマット確認
- precomputed_poems.json として保存

# 3週目: フロントエンド統合
- ハッシュ計算ロジック実装
- オフラインモード切り替え機能
- フォールバック処理
```

### Phase 2: 品質評価

```
評価指標:
1. カバレッジ: 実ユーザーの選択のうち何%がヒットするか
2. ユーザー満足度: デモ参加者のフィードバック
3. フォールバック頻度: ヒットしない場合の頻度

改善:
- カバレッジが低い場合、パターン数を増やす（例: 2,000 → 14円）
- フォールバックの品質向上（テンプレート改善）
```

### Phase 3: 長期的展望（必要に応じて）

```
ファインチューニング実験（Phase 2の結果次第）:
1. Phase 0検証（100件、0.7円）
   - 20Bモデルの潜在能力確認
   - 品質が許容範囲内か評価

2. 判断:
   ✓ 品質が50%以上 → Phase 1（500件）に進む
   × 品質が50%未満 → ファインチューニング断念、他の案を採用

3. Phase 1実装（500件、3.5円）
   - ファインチューニング実行
   - 品質評価
   - Geminiとの比較

4. 最終判断:
   ✓ 品質が70%以上 → Phase 2（5,000件、35円）に進む
   × 品質が70%未満 → ファインチューニング断念
```

---

## 7. 結論と推奨事項

### 7.1 総合評価

| アプローチ | 品質 | コスト | 開発工数 | オフライン | 推奨度 |
|-----------|------|--------|----------|-----------|---------|
| 現状（Gemini API） | ★★★★★ | ★★★★★ | ★★★★★ | ✗ | ★★★★★ |
| 事前生成（推奨案3） | ★★★★★ | ★★★★★ | ★★★★☆ | ✓ | ★★★★★ |
| プロンプトキャッシング（推奨案4） | ★★★★★ | ★★★★★ | ★★★★☆ | ✗ | ★★★★☆ |
| 大型モデル70B（推奨案1） | ★★★★☆ | ★☆☆☆☆ | ★★★☆☆ | ✓ | ★★★☆☆ |
| プロンプト簡素化（推奨案2） | ★★☆☆☆ | ★★★★☆ | ★★☆☆☆ | ✓ | ★★☆☆☆ |
| 20B FT（質問の案） | ★☆☆☆☆ | ★★★★☆ | ★★☆☆☆ | ✓ | ★☆☆☆☆ |

### 7.2 最終推奨

**ユースケース別の推奨事項:**

#### ケース1: ローカル開発環境でのオフラインデモ（数時間程度）
→ **推奨案3: 事前生成 + オフライン配信**
- コスト: 7円（1,000パターン）
- 開発工数: 1-2週間
- 品質: Geminiと同等
- デモには十分な体験を提供

#### ケース2: 継続的なオフライン運用（商用など）
→ **推奨案1: 大型モデル（70B+）のローカル実行**
- 初期投資: 30-50万円（GPU）
- 品質: Geminiに近い
- 長期的にはコスト効率が良い

#### ケース3: オンライン環境が利用可能
→ **現状維持 + プロンプトキャッシング**
- 最高品質を維持
- コストは既に十分低い（月7円程度）
- さらなる削減も可能

#### ケース4: 実験として試したい
→ **Phase 0検証（100件、0.7円）を実施**
- リスクが極めて低い
- 明確な判断基準（品質50%以上）を設定
- 失敗しても損失は1円未満

### 7.3 ファインチューニングへの最終見解

**20Bモデルのファインチューニングは、以下の理由から推奨しません:**

1. **品質リスク**: 既存の20B生成例が示す品質レベルから、ファインチューニングだけでGeminiレベルに到達することは極めて困難
2. **コスト対効果**: 現状のGemini APIが非常に安価（月7円）で、代替手段のメリットが薄い
3. **開発リスク**: データ生成・検証・トレーニング・評価に相当な工数が必要だが、成果が不確実
4. **より良い代替案の存在**: 事前生成アプローチなら、同等のコストでGemini品質を維持できる

**ただし、実験的に試す価値はあります:**
- Phase 0（100件、0.7円）は極めて低リスク
- 万が一、予想を超える品質が得られれば、大きな発見
- 失敗しても得られる知見は有益

---

## 8. 次のステップ

### 即座に実行可能なアクション

1. **推奨案3の実装準備**
   ```bash
   # 1. スクリプトのひな型作成
   mkdir -p scripts/dataset
   touch scripts/dataset/generate_precomputed_poems.ts

   # 2. パターン生成ロジック実装
   # 3. Gemini API連携
   # 4. データ保存
   ```

2. **Phase 0検証（オプション）**
   ```bash
   # 100件のデータセットで実現性確認
   npm run generate-ft-dataset -- --samples=100

   # ファインチューニング（Together.ai / Vertex AI）
   # 品質評価
   ```

3. **大型モデルの検証（予算次第）**
   ```bash
   # LM Studioで Llama 3.1 70B をローカル実行
   # 既存のプロンプトをそのまま試す
   # 品質を評価
   ```

### 評価基準の明確化

**品質評価の指標:**
- 文字数遵守率: 95%以上
- タイトル選択率: 100%（候補から選択）
- 詩的表現力: 主観評価（1-5点、Gemini=5点）
- ネガティブ条件の隠蔽度: 主観評価（1-5点）
- 全体的な満足度: デモ参加者のフィードバック

**判断基準:**
- Geminiの70%以上の品質 → 採用を検討
- 50-70%の品質 → デモ用途なら許容範囲
- 50%未満 → 不採用

---

## 付録: 参考資料

### A. ファインチューニング関連リソース

**プロバイダー:**
- [Together.ai](https://www.together.ai/): Llama 2/3のファインチューニング
- [Google Vertex AI](https://cloud.google.com/vertex-ai): Gemini/PaLMのファインチューニング
- [OpenAI](https://platform.openai.com/docs/guides/fine-tuning): GPT-3.5/4のファインチューニング

**フレームワーク:**
- [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl): ファインチューニング統合フレームワーク
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory): 効率的なファインチューニング
- [Unsloth](https://github.com/unslothai/unsloth): 高速ファインチューニング

### B. ローカル実行環境

**推奨ツール:**
- [LM Studio](https://lmstudio.ai/): GUI、簡単なセットアップ
- [Ollama](https://ollama.ai/): CLI、軽量
- [text-generation-webui](https://github.com/oobabooga/text-generation-webui): 高度なカスタマイズ

**モデル候補:**
- Llama 3.1 70B（推奨）
- Qwen 2.5 72B（多言語対応強化）
- Mixtral 8x22B（高品質、要大容量VRAM）

### C. コスト試算の補足

**Gemini API（現状）:**
```
Flash 1.5:
- Input: $0.00001875/1K tokens
- Output: $0.000075/1K tokens
- Context Cache (hit): $0.000001875/1K tokens（90%削減）

Pro 1.5（高品質が必要な場合）:
- Input: $0.00125/1K tokens
- Output: $0.005/1K tokens
```

**Together.ai（ファインチューニング）:**
```
トレーニング: $0.0008/1K tokens
推論（Llama 2 70B FT）: $0.0009/1K tokens
```

### D. 技術的詳細

**量子化の影響:**
```
パラメータ精度と品質:
- FP16（16bit）: フル品質（ベースライン）
- Int8（8bit）: 品質劣化 <5%、メモリ1/2
- Int4（4bit）: 品質劣化 10-15%、メモリ1/4
- Int3/2: 品質劣化 >20%、非推奨

創造的タスクでは、量子化による品質劣化が顕著に現れます。
```

---

**文書作成日**: 2025年10月（想定）
**対象プロジェクト**: Mansion Poem
**作成者**: Claude (Anthropic)
**ステータス**: 提案・検討段階
